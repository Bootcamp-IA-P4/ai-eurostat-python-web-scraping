ğŸŒ Py-Web-Scraping-03

<img alt="GPLv3 License" src="https://img.shields.io/badge/License-GPLv3-blue.svg">

<img alt="Python Version" src="https://img.shields.io/badge/Python->=3.13-blue">

<img alt="Selenium Version" src="https://img.shields.io/badge/Selenium->=4.29.0-green">

<img alt="Django Version" src="https://img.shields.io/badge/Django->=5.1.7-darkgreen">
ğŸ“– DescripciÃ³n del Proyecto
Py-Web-Scraping-03 es un proyecto diseÃ±ado para realizar scraping de datos desde la web de Eurostat, una plataforma que proporciona estadÃ­sticas y datos econÃ³micos de la UniÃ³n Europea. Este proyecto utiliza herramientas avanzadas como Selenium, BeautifulSoup, y Pandas para automatizar la extracciÃ³n, procesamiento y anÃ¡lisis de datos. AdemÃ¡s, los datos extraÃ­dos pueden ser exportados a formatos como Excel para su posterior anÃ¡lisis.

El proyecto tambiÃ©n incluye una integraciÃ³n con Django, lo que permite gestionar los datos extraÃ­dos a travÃ©s de una interfaz web.

ğŸš€ CaracterÃ­sticas Principales
AutomatizaciÃ³n del scraping: Uso de Selenium para interactuar con tablas dinÃ¡micas y contenido renderizado por JavaScript.
Procesamiento de datos: Limpieza y anÃ¡lisis de datos con Pandas.
ExportaciÃ³n: GeneraciÃ³n de archivos Excel con los datos extraÃ­dos utilizando OpenPyXL.
Interfaz web: GestiÃ³n de los datos extraÃ­dos a travÃ©s de un backend basado en Django.
Compatibilidad: DiseÃ±ado para Python 3.13 o superior.

py-web-scraping-03/
â”œâ”€â”€ scraper/
â”‚   â”œâ”€â”€ eurostat_scraper.py       # CÃ³digo principal para el scraping
â”‚   â”œâ”€â”€ utils.py                  # Funciones auxiliares
â”‚   â””â”€â”€ tests/                    # Pruebas unitarias
â”œâ”€â”€ manage.py                     # Script de Django para gestionar el proyecto
â”œâ”€â”€ requirements.txt              # Dependencias del proyecto
â”œâ”€â”€ pyproject.toml                # ConfiguraciÃ³n del proyecto
â”œâ”€â”€ README.md                     # DocumentaciÃ³n del proyecto
â”œâ”€â”€ screenshots/                  # Capturas de pantalla generadas durante el scraping
â””â”€â”€ logs/                         # Archivos de log para depuraciÃ³n



ğŸ› ï¸ Requisitos Previos
Antes de comenzar, asegÃºrate de tener instalados los siguientes componentes:

Python 3.13 o superior
Google Chrome (o Firefox si usas Geckodriver)
ChromeDriver o GeckoDriver (administrado automÃ¡ticamente por webdriver-manager)

ğŸ› ï¸ InstalaciÃ³n en Linux/MacOS
OpciÃ³n 1: Usando pip

1.Crear un entorno virtual:
python3 -m venv venv
source venv/bin/activate

2.Instalar las dependencias:
pip install -r requirements.txt

3.Verificar la instalaciÃ³n:
python --version
pip list

----
OpciÃ³n 2: Usando uv (alias de pipenv)

1.Instalar pipenv (si no lo tienes instalado):
pip install pipenv

2.Crear el entorno virtual e instalar dependencias:
uv install

3.Sincronizar dependencias:
uv sync

4.Activar el entorno virtual:
uv shell

5.Verificar la instalaciÃ³n:
python --version
uv graph

----

ğŸ› ï¸ InstalaciÃ³n en Windows

OpciÃ³n 1: Usando pip

1.Crear un entorno virtual:
python -m venv venv
venv\Scripts\activate

2.Instalar las dependencias:
pip install -r requirements.txt

3.Verificar la instalaciÃ³n:
python --version
pip list

----

OpciÃ³n 2: Usando uv (alias de pipenv)

1.Instalar pipenv (si no lo tienes instalado):
pip install pipenv

2.Crear el entorno virtual e instalar dependencias:
uv install

3.Sincronizar dependencias:
uv sync

4.Activar el entorno virtual:
uv shell

5.Verificar la instalaciÃ³n:
python --version
uv graph

----

âš ï¸ Nota Importante

- uv install: Instala las dependencias especificadas en pyproject.toml y genera un archivo Pipfile.lock.

- uv sync: Asegura que las dependencias instaladas en el entorno virtual coincidan exactamente con las especificadas en el archivo Pipfile.lock.

- No ejecutes ambos mÃ©todos (pip y uv) al mismo tiempo. Elige uno de los dos.

